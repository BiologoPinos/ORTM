---
title: "PISCO_urchin_tuffy"
author: "Andrés Pinos-Sánchez"
date: "2025-05-15"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Load libraries
library(ggplot2)
library(dplyr)
library(readr)
library(tidyverse)
library(mcmcplots)
library(MCMCvis)
library(coda)

#Clear
rm(list = ls()) #environment

set.seed(123)
```

##AIM OF THE SCRIPT
Obtain the year to tear variability of urchin recruitment (std) in Oregon


##INPUT RAW DATA

This data is from PISCO surveys posted by MENGE, for intertidal recruitmentacross the coast
O.G. data (look for all "tuffy" data-sets): https://data.piscoweb.org/metacatui/view/doi%3A10.6085%2FAA%2Fpisco_recruitment.1477.1
```{r}
# # Input data from PISCO, data name corresponds to collection year (not deployment)
# PISCO_data_1989 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.124.1.csv")  |> mutate(year = 1989, .before = 1)
# PISCO_data_1990 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.126.1.csv")  |> mutate(year = 1990, .before = 1)
# PISCO_data_1991 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.128.1.csv")  |> mutate(year = 1991, .before = 1)
# PISCO_data_1992 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.130.1.data") |> mutate(year = 1992, .before = 1)
# PISCO_data_1993 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.132.1.data") |> mutate(year = 1993, .before = 1)
# PISCO_data_1994 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.134.1.csv")  |> mutate(year = 1994, .before = 1)
# PISCO_data_1995 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.136.1.data") |> mutate(year = 1995, .before = 1)
# PISCO_data_1996 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.138.1.data") |> mutate(year = 1996, .before = 1)
# # 1997 skipped
# PISCO_data_1998 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.140.1.data") |> mutate(year = 1998, .before = 1)
# PISCO_data_1999 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.142.1.data") |> mutate(year = 1999, .before = 1)
# PISCO_data_2000 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.144.1.csv")  |> mutate(year = 2000, .before = 1)
# PISCO_data_2001 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.146.1.data") |> mutate(year = 2001, .before = 1)
# PISCO_data_2002 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.148.1.csv")  |> mutate(year = 2002, .before = 1)
# PISCO_data_2003 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.150.1.data") |> mutate(year = 2003, .before = 1)
# PISCO_data_2004 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.152.1.csv")  |> mutate(year = 2004, .before = 1)
# PISCO_data_2005 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.154.1.csv")  |> mutate(year = 2005, .before = 1)
# PISCO_data_2006 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.156.1.data") |> mutate(year = 2006, .before = 1)
# PISCO_data_2007 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.1364.1.data")|> mutate(year = 2007, .before = 1)
# PISCO_data_2008 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.1366.1.csv") |> mutate(year = 2008, .before = 1)
# PISCO_data_2009 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.1438.1.csv") |> mutate(year = 2009, .before = 1)
# PISCO_data_2010 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.1446.1.csv") |> mutate(year = 2010, .before = 1)
# PISCO_data_2011 <- read_csv("Datasets/doi_10.6085_AA_pisco_recruitment.1464.1.txt") |> mutate(year = 2011, .before = 1)
# 
# # Combine all datasets
# PISCO_all_years <- bind_rows(PISCO_data_1989, PISCO_data_1990, PISCO_data_1991, 
#                              PISCO_data_1992, PISCO_data_1993, PISCO_data_1994, 
#                              PISCO_data_1995, PISCO_data_1996, PISCO_data_1998,
#                              PISCO_data_1999, PISCO_data_2000, PISCO_data_2001,
#                              PISCO_data_2002, PISCO_data_2003, PISCO_data_2004, 
#                              PISCO_data_2005, PISCO_data_2006, PISCO_data_2007, 
#                              PISCO_data_2008, PISCO_data_2009, PISCO_data_2010, 
#                              PISCO_data_2011)

# # Print and explore
# print()
# summary()
 
# Save table
# write.csv(PISCO_all_years, "PISCO_all_years.csv", row.names = FALSE)

```

##INPUT DATA
```{r}
# Load PISCO data
pisco <- read_csv("PISCO_all_years.csv") #PISCO_all_years, #read_csv("PISCO_all_years.csv"), # source("PISCO_data_prep.R")

# Filter for taxa 66,67,70 and drop unwanted sites
urchins_raw <- pisco %>%
  filter(count_classcode %in% c("66","67","70"), # data 2001 - 2011
         !site_code %in% c("CMEN00","CMES00","IFBRXX","KHLX00",
                           "PSGX00","SHCX00","TRHX00","IPTAXX")) # 14 sites

# Group (transects) by year, site_code, zone, replicate, 
# then sum/mean within transects, and compute annual mean
urchins <- urchins_raw %>%
  group_by(year, site_code, zone, replicate) %>%
  summarise(count = sum(count),
            .groups = "drop")

# Log-transform counts (add 1 to avoid log(0))
urchins <- urchins %>%
  mutate(log_count = log(count + 1))

# Explore data
hist(urchins$count)
hist(urchins$log_count)

```

## MODEL URCHIN RECRUITMENT

Objective:
1. estimate the normalized year to year variance (SD) by site of incoming recruits...
   using a Poisson distribution for zero inflated values. 
Note: sea urchin recruitment follows a log-normal distribution

Aim:
I'd be building a hierarchical structure where my incoming settlers data informs
a log-normal distributed annual means, and those annual means inform a normally 
distributed year to year variance (SD). I'll use a zero inflated poisson distribution

Model(s) method(s):
1. brms
2. nimble


## 1) BRMS VERSION OF THE MODEL
```{r}
# Load brms
library(brms)
library(posterior)

# Model
brms_model <- brm(formula = count ~ site_code + (1 | site_code / year),
                   family  = zero_inflated_poisson(), 
                   data    = urchins,
                   iter    = 4000,
                   warmup  = 1000,
                   thin    = 3,
                   chains  = 3,
                   cores   = 3)

summary(brms_model)

plot(brms_model)

# Get posterior draws to get the temporal (normalized) standard deviation (noise)
post <- as_draws_df(brms_model)

log_sd <- post[["sd_site_code:year__Intercept"]]

mean(log_sd) #number we want
```

## 2) NIMBLE VERSION OF THE MODEL
```{r}
# Load nimble
library(nimble)
source("attach.nimble.R")

# Step 1 prep data
urchins <- urchins %>%
  mutate(presence = as.numeric(count > 0),
         site_idx = as.integer(as.factor(site_code)),
         year_idx = as.integer(as.factor(year)),
         site_year_idx = as.integer(as.factor(paste(site_code, year, sep = "_"))))

# Step 2 nimble code/model
nimble_code <- nimbleCode({
  
  # Hyper priors
  tau_eps ~ dgamma(0.1, 0.1)
  sd_eps  <- 1 / sqrt(tau_eps)  # This is the SD you're after
  pi      ~ dbeta(1, 1)     # Common zero-inflation prob across all obs

  # Priors for site fixed effects (intercepts on log-scale)
  for (s in 1:n_sites) {
    
    beta_site[s] ~ dnorm(0, 0.001)
    
  }#s

  # Random effects for site:year (process model)
  for (j in 1:n_site_years) {
    
    eps[j] ~ dnorm(0, tau_eps)
    
  }#j

  # Zero-inflation parameter
  for (i in 1:n_obs) {
    
    psi[i] ~ dbern(pi)  # Zero-inflation indicator

    # Linear predictor (process model)
    log(lambda[i]) <- beta_site[site_idx[i]] + eps[site_year_idx[i]]

    # Observation model
    count[i] ~ dpois(psi[i] * lambda[i])  # Zero-inflated Poisson
    
  }#n_obs
  
})#nimble_code

# Step 3 specify parameters, data, constants, and initial values
parameters <- c("sd_eps", "tau_eps", "pi")

nimble_data <- list(count = urchins$count)

nimble_constants <- list(n_obs         = nrow(urchins),
                         n_sites       = length(unique(urchins$site_idx)),
                         n_site_years  = length(unique(urchins$site_year_idx)),
                         site_idx      = urchins$site_idx,
                         site_year_idx = urchins$site_year_idx)

initial_conditions <- list(beta_site = rep(0, n_sites),
                           eps       = rep(0, n_site_years),
                           tau_eps   = 1,
                           pi        = 0.2,
                           psi       = rep(1, n_obs))

# Step 4 compile and Run MCMC
nimble_model <- nimbleMCMC(code      = nimble_code, 
                           constants = nimble_constants, 
                           data      = nimble_data, 
                           inits     = initial_conditions,
                           monitors  = parameters,
                           niter     = 40000,
                           nburnin   = 20000,
                           nchains   = 3,
                           thin      = 40,
                           summary   = TRUE,
                           samplesAsCodaMCMC = TRUE)

# Step 5 analyze model results
summary(nimble_model)
print(nimble_model$summary)
attach.nimble(nimble_model$samples)
# mcmcplot(nimble_model$samples)

# Density plots
densplot(nimble_model$samples[, "sd_eps"],
         main = "Posterior density of normalized recruitment variance",
         xlab = "Recruirtment normalized variance (sd)",
         ylab = "Posterior density")

# Posterior check
MCMCtrace(object = nimble_model$samples,
          pdf    = FALSE, # no export to PDF
          ind    = TRUE, # separate density lines per chain
          params = c("sd_eps", "tau_eps", "pi"))

apply(sd_eps,2,median)
apply(sd_eps,2,quantile,c(0.025,0.5,0.975))

# Step 6 extract the standard deviation of interest
mean(sd_eps)  #this is the temporal (within-site/year) SD on norm scale

```

## WORKING VERSION OF THE MODEL
```{r}
# Load nimble
library(nimble)
source("attach.nimble.R")

# Nimble model - Fun begins
model_code <- nimbleCode({
  
  # Hyperpriors
  mu          ~ dnorm(0, 1)             # Overall mean of log recruitment
  sigma_year  ~ T(dt(0, 1, 1), 0, )     # Half-Cauchy for year effect SD
  sigma_proc  ~ T(dt(0, 1, 1), 0, )     # Half-Cauchy for process SD
  sigma_obs   ~ T(dt(0, 1, 1), 0, )     # Half-Cauchy for observation SD
  
  # Random year effects
  for(j in 1:n_years){
    
    year_effect[j] <- dnorm(mu, sd = sigma_year)
    
  }#j
  
  # Process and Observational model
  for(j in 1:n_years) {
    
    # Process model: latent true log recruitment per year
    log_recruit[j] <- dnorm(year_effect[j], sd = sigma_proc)
    
  }#j
  
  # Observation model: observed log counts around latent recruitment
  for(i in 1:n_obs) {
    
    log_count[i] ~ dnorm(mean = log_recruit[year_index[i]], sd = sigma_obs)
    
  }#i
  
})#model_code


# Prep for MCMC

# Constants & data
parameters <- c("mu", "sigma_year", "sigma_proc", "sigma_obs", "year_effect", "log_recruit")

nimble_constants <- list(n_obs = nrow(urchins),
                         n_years = length(sort(unique(urchins$year))),
                         year_index = match(urchins$year, sort(unique(urchins$year))))

nimble_data <- list(log_count = urchins$log_count)

# MCMC settings
ni <- 50000
nb <- 10000
nt <- 40
nc <- 3

# Run MCMC
mcmc_output <- nimbleMCMC(code      = model_code,
                          data      = nimble_data,
                          constants = nimble_constants,
                          monitors  = parameters,
                          niter     = ni,
                          nburnin   = nb,
                          nchains   = nc,
                          thin      = nt,
                          summary   = TRUE,
                          samplesAsCodaMCMC = TRUE)

# MCMC outputs
attach.nimble(mcmc_output$samples)
summary(mcmc_output)
print(mcmc_output$summary)
mcmcplot(mcmc_output$samples)

# Non-normal year to year variance of recruitment
densplot(mcmc_output$samples[, "sigma_obs"],
         main = "Posterior density of Log-Normal recruitment variance",
         xlab = "Log-Normal variance (sd)")
mean(sigma_obs) #number I want in log_normal space

# Normalize the year effects (back-transform from log-scale)
norm_sd <- exp(sigma_obs)  # back to count scale
mean(norm_sd) # number I want in normal space

#Plot posterior density of SD
norm_sd_mcmc <- as.mcmc(norm_sd)
plot(density(norm_sd_mcmc),
     main = "Posterior density of recruitment norm_sd",
     xlab = "Normalized variance (sd)")

```
## POSTERIOR PREDICTIVE CHECK
```{r}
MCMCtrace(object = mcmc_output$samples,
          pdf = FALSE, # no export to PDF
          ind = TRUE, # separate density lines per chain
          params = "sigma_obs")

median(sigma_obs)

apply(sigma_obs,2,median)
apply(sigma_obs,2,quantile,c(0.025,0.5,0.975))

```

## OLDER VERSION OF THE MODEL
```{r}
# Nimble model - Fun begins
model_code <- nimbleCode({

  # Hyperpriors
  mu         ~ dnorm(0, 1)           # Overall mean
  sigma_year ~ T(dt(0, 1, 1), 0, )   # Half-Cauchy for year SD
  sigma_obs  ~ T(dt(0, 1, 1), 0, )   # Half-Cauchy for residual SD

  # Random year effects
  for(j in 1:n_years){
    year_effect[j] ~ dnorm(mu, sd = sigma_year)
  }#j

  # Observation model
  for(i in 1:n_obs){

    log_count[i] ~ dnorm(mean = year_effect[year_index[i]], sd = sigma_obs)

  }#i

})#model_code


# Prep for MCMC

# Constants & data
parameters <- c("mu", "sigma_year", "sigma_obs", "year_effect")

nimble_constants <- list(n_obs = nrow(urchins),
                         n_years = length(sort(unique(urchins$year))),
                         year_index = match(urchins$year, sort(unique(urchins$year))))

nimble_data <- list(log_count = urchins$log_count)

# MCMC settings
ni <- 50000
nb <- 10000
nt <- 40
nc <- 3

# Run MCMC
mcmc_output <- nimbleMCMC(code      = model_code,
                          data      = nimble_data,
                          constants = nimble_constants,
                          monitors  = parameters,
                          niter     = ni,
                          nburnin   = nb,
                          nchains   = nc,
                          thin      = nt,
                          summary   = TRUE,
                          samplesAsCodaMCMC = TRUE)

# MCMC outputs
attach.nimble(mcmc_output$samples)
summary(mcmc_output)
print(mcmc_output$summary)
mcmcplot(mcmc_output$samples)

densplot(mcmc_output$samples[, "sigma_obs"],
         main = "Posterior density of normalized recruitment variance\n(exp(σ²) - 1)",
         xlab = "Normalized variance")

# Normalize the year effects (back-transform from log-scale)
year_mean_recruit <- exp(year_effect)  # back to count scale
year_mean_norm <- sweep(year_mean_recruit, 1, rowMeans(year_mean_recruit), "/")
norm_sd <- apply(year_mean_norm, 1, sd)
mean(norm_sd) # number I need

# Summary of normalized SD
hist(norm_sd, main = "Posterior of Normalized Year-to-Year SD",
     xlab = "Normalized SD")
mean(norm_sd)
quantile(norm_sd, probs = c(0.025, 0.5, 0.975))


#Plot posterior density of CV
norm_sd_mcmc <- as.mcmc(norm_sd)
plot(density(norm_sd_mcmc),
     main = "Posterior density of recruitment norm_sd",
     xlab = "Norm_sd")

```


